{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-08T16:25:11.967661Z","iopub.status.busy":"2024-03-08T16:25:11.966636Z","iopub.status.idle":"2024-03-08T16:25:11.978880Z","shell.execute_reply":"2024-03-08T16:25:11.978017Z","shell.execute_reply.started":"2024-03-08T16:25:11.967612Z"},"trusted":true},"outputs":[],"source":["class Data:\n","    def __init__(self, data_dir=\"data/FB15k-237/\", reverse=False):\n","        self.train_data = self.load_data(data_dir, \"train\", reverse=reverse)\n","        self.valid_data = self.load_data(data_dir, \"valid\", reverse=reverse)\n","        self.test_data = self.load_data(data_dir, \"test\", reverse=reverse)\n","        self.data = self.train_data + self.valid_data + self.test_data\n","        self.entities = self.get_entities(self.data)\n","        self.relations = self.get_relations(self.data)\n","        self.train_relations = self.get_relations(self.train_data)\n","        self.valid_relations = self.get_relations(self.valid_data)\n","        self.test_relations = self.get_relations(self.test_data)\n","\n","    @staticmethod\n","    def load_data(data_dir, data_type=\"train\", reverse=False):\n","        with open(\"%s%s.txt\" % (data_dir, data_type), \"r\") as f:\n","            data = f.read().strip().split(\"\\n\")\n","            data = [i.split() for i in data]\n","            if reverse:\n","                data += [[i[2], i[1] + \"_reverse\", i[0]] for i in data]\n","        return data\n","\n","    @staticmethod\n","    def get_relations(data):\n","        relations = sorted(list(set([d[1] for d in data])))\n","        return relations\n","\n","    @staticmethod\n","    def get_entities(data):\n","        entities = sorted(list(set([d[0] for d in data] + [d[2] for d in data])))\n","        return entities\n"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-03-08T16:27:57.648066Z","iopub.status.busy":"2024-03-08T16:27:57.647670Z","iopub.status.idle":"2024-03-08T16:28:09.923560Z","shell.execute_reply":"2024-03-08T16:28:09.922455Z","shell.execute_reply.started":"2024-03-08T16:27:57.648037Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: wandb in /opt/conda/lib/python3.10/site-packages (0.16.3)\n","Requirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb) (8.1.7)\n","Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.1.41)\n","Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (2.31.0)\n","Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (5.9.3)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.40.5)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (0.4.0)\n","Requirement already satisfied: PyYAML in /opt/conda/lib/python3.10/site-packages (from wandb) (6.0.1)\n","Requirement already satisfied: setproctitle in /opt/conda/lib/python3.10/site-packages (from wandb) (1.3.3)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from wandb) (69.0.3)\n","Requirement already satisfied: appdirs>=1.4.3 in /opt/conda/lib/python3.10/site-packages (from wandb) (1.4.4)\n","Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from wandb) (3.20.3)\n","Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"]}],"source":["! pip3 install wandb"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-03-08T16:28:27.567145Z","iopub.status.busy":"2024-03-08T16:28:27.566720Z","iopub.status.idle":"2024-03-08T16:28:39.601436Z","shell.execute_reply":"2024-03-08T16:28:39.600514Z","shell.execute_reply.started":"2024-03-08T16:28:27.567115Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/plain":["True"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["import wandb\n","\n","wandb.login()"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-03-08T18:28:19.337626Z","iopub.status.busy":"2024-03-08T18:28:19.337280Z","iopub.status.idle":"2024-03-08T18:28:54.379258Z","shell.execute_reply":"2024-03-08T18:28:54.378065Z","shell.execute_reply.started":"2024-03-08T18:28:19.337599Z"},"trusted":true},"outputs":[{"data":{"text/html":["Finishing last run (ID:ozatkkcz) before initializing another..."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Hits @1</td><td>▁▂▂▃▃▃▄▄▄▅▅▅▆▆▇▇██</td></tr><tr><td>Hits @10</td><td>▁▂▃▄▅▅▅▆▆▆▇▇▇▇████</td></tr><tr><td>Hits @3</td><td>▁▂▃▄▄▄▅▅▆▆▆▆▇▇▇███</td></tr><tr><td>Mean reciprocal rank</td><td>▁▂▃▄▄▄▅▅▅▆▆▆▆▇▇███</td></tr><tr><td>T norm</td><td>▁▂▄▄▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇████████████</td></tr><tr><td>train_mean_loss</td><td>█▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_step_loss</td><td>█▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Hits @1</td><td>0.09438</td></tr><tr><td>Hits @10</td><td>0.25012</td></tr><tr><td>Hits @3</td><td>0.15279</td></tr><tr><td>Mean reciprocal rank</td><td>0.14616</td></tr><tr><td>T norm</td><td>371591.96875</td></tr><tr><td>train_mean_loss</td><td>0.00448</td></tr><tr><td>train_step_loss</td><td>0.00433</td></tr><tr><td>val_loss</td><td>0.02876</td></tr></table><br/></div></div>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run <strong style=\"color:#cdcd00\">serene-morning-2</strong> at: <a href='https://wandb.ai/sudakov/v2/runs/ozatkkcz' target=\"_blank\">https://wandb.ai/sudakov/v2/runs/ozatkkcz</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: <code>./wandb/run-20240308_174721-ozatkkcz/logs</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Successfully finished last run (ID:ozatkkcz). Initializing new run:<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["wandb version 0.16.4 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.16.3"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240308_182819-t2zt3t7l</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/sudakov/v3/runs/t2zt3t7l' target=\"_blank\">generous-thunder-1</a></strong> to <a href='https://wandb.ai/sudakov/v3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/sudakov/v3' target=\"_blank\">https://wandb.ai/sudakov/v3</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/sudakov/v3/runs/t2zt3t7l' target=\"_blank\">https://wandb.ai/sudakov/v3/runs/t2zt3t7l</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/sudakov/v3/runs/t2zt3t7l?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x78f992b76680>"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["wandb.init(\n","    # set the wandb project where this run will be logged\n","    project=\"v3\",\n",")"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-03-08T17:47:58.620508Z","iopub.status.busy":"2024-03-08T17:47:58.619537Z","iopub.status.idle":"2024-03-08T17:48:11.223310Z","shell.execute_reply":"2024-03-08T17:48:11.222162Z","shell.execute_reply.started":"2024-03-08T17:47:58.620463Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: tucker_riemopt in /opt/conda/lib/python3.10/site-packages (1.0.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.21.4 in /opt/conda/lib/python3.10/site-packages (from tucker_riemopt) (1.26.4)\n","Requirement already satisfied: opt-einsum<4.0.0,>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from tucker_riemopt) (3.3.0)\n","Requirement already satisfied: scipy<2.0.0,>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from tucker_riemopt) (1.11.4)\n"]}],"source":["! pip3 install tucker_riemopt"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-08T17:48:11.226074Z","iopub.status.busy":"2024-03-08T17:48:11.225678Z","iopub.status.idle":"2024-03-08T17:48:11.233040Z","shell.execute_reply":"2024-03-08T17:48:11.231775Z","shell.execute_reply.started":"2024-03-08T17:48:11.226035Z"},"trusted":true},"outputs":[],"source":["import torch\n","import numpy as np\n","from torch import nn\n","from torch.nn.init import xavier_normal_\n","from tucker_riemopt import SFTucker\n","\n","from torch.optim import Optimizer\n","from tucker_riemopt import SFTuckerRiemannian"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-03-08T18:29:03.095240Z","iopub.status.busy":"2024-03-08T18:29:03.094350Z","iopub.status.idle":"2024-03-08T18:29:03.112826Z","shell.execute_reply":"2024-03-08T18:29:03.111858Z","shell.execute_reply.started":"2024-03-08T18:29:03.095207Z"},"trusted":true},"outputs":[],"source":["class SFTuckER:\n","    def __init__(self, d, d1, d2):\n","        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","        self.rank = (d2, d1, d1)\n","        self.E = torch.rand((len(d.entities), d1), device=device)\n","        self.R = torch.rand((len(d.relations), d2), device=device)\n","        self.W = torch.tensor(np.random.uniform(-1, 1, (d2, d1, d1)), dtype=torch.float, device=device)\n","        \n","    def parameters(self):\n","        return nn.ParameterList([self.W, self.E, self.R])\n","\n","    def init(self):\n","        xavier_normal_(self.E.data)\n","        xavier_normal_(self.R.data)\n","        # with torch.no_grad():\n","        #     self.E.weight.data = torch.linalg.qr(self.E.weight)[0]\n","        #     self.R.weight.data = torch.linalg.qr(self.R.weight)[0]\n","\n","    def forward(self, e_idx, r_idx):\n","        relations = self.R[r_idx, :]\n","        subjects = self.E[e_idx, :]\n","        preds = torch.einsum(\"abc,da->dbc\", self.W, relations)\n","        preds = torch.bmm(subjects.view(-1, 1, subjects.shape[1]), preds).view(-1, subjects.shape[1])\n","        preds = preds @ self.E.T\n","        return torch.sigmoid(preds)\n","\n","\n","class RGD(Optimizer):\n","    def __init__(self, model_parameters, rank, max_lr):\n","        self.rank = rank\n","        self.max_lr = max_lr\n","        self.lr = max_lr\n","        self.direction = None\n","        self.loss = None\n","\n","        defaults = dict(rank=rank, max_lr=self.max_lr, lr=self.lr)\n","        params = model_parameters\n","        super().__init__(params, defaults)\n","\n","    def fit(self, loss_fn, model, normalize_grad=False):\n","        x_k = SFTucker(model.W.data, [model.R.data], num_shared_factors=2, shared_factor=model.E.data)\n","        rgrad, self.loss = SFTuckerRiemannian.grad(loss_fn, x_k)\n","        rgrad_norm = rgrad.norm().detach()\n","\n","        if normalize_grad:\n","            normalizer = normalize_grad / rgrad_norm\n","        else:\n","            normalizer = 1\n","\n","        self.direction = normalizer * rgrad\n","        return rgrad_norm\n","\n","    @torch.no_grad()\n","    def step(self):\n","        W, E, R = self.param_groups[0][\"params\"]\n","\n","        x_k = self.direction.point\n","        x_k = (-self.param_groups[0][\"lr\"]) * self.direction + SFTuckerRiemannian.TangentVector(x_k)\n","        x_k = x_k.construct().round(self.rank)\n","\n","        W.data.add_(x_k.core - W)\n","        R.data.add_(x_k.regular_factors[0] - R)\n","        E.data.add_(x_k.shared_factor - E)\n","\n","\n","class SFTuckerAdam(RGD):\n","    def __init__(self, params, rank, max_lr, betas=(0.9, 0.999), eps=1e-8, step_velocity=1):\n","        super().__init__(params, rank, max_lr)\n","        self.betas = betas\n","        self.eps = eps\n","        self.step_velocity = step_velocity\n","        \n","        self.momentum = None\n","        self.second_momentum = torch.zeros(1, device=device)\n","        \n","        self.step_t = 1\n","\n","    def fit(self, loss_fn, model, normalize_grad=False):\n","        \"\"\"\n","        Computes the Riemannian gradient of `loss_fn` at point `x_k`.\n","\n","        :param loss_fn: smooth scalar-valued loss function\n","        :param x_k: current solution approximation\n","        :param normalize_grad: Can be `False` or float. If `False`, the Riemannian gradient will not be normalized. Otherwise, gradient will\n","         be normalized to `normalize_grad`.\n","        :return: Frobenius norm of the Riemannian gradient.\n","        \"\"\"\n","        x_k = SFTucker(model.W.data, [model.R.data], num_shared_factors=2, shared_factor=model.E.data)\n","        rgrad, self.loss = SFTuckerRiemannian.grad(loss_fn, x_k)\n","        rgrad_norm = rgrad.norm().detach()\n","        if self.momentum is not None:\n","            self.momentum = SFTuckerRiemannian.project(x_k, self.momentum.construct())\n","            self.momentum = self.betas[0] * self.momentum + (1 - self.betas[0]) * rgrad\n","        else:\n","            self.momentum = (1 - self.betas[0]) * rgrad\n","        self.second_momentum = self.betas[1] * self.second_momentum + (1 - self.betas[1]) * rgrad_norm ** 2\n","        second_momentum_corrected = self.second_momentum / (1 - self.betas[1] ** (self.step_t // self.step_velocity + 1))\n","        bias_correction_ratio = (1 - self.betas[0] ** (self.step_t // self.step_velocity + 1)) * torch.sqrt(\n","            second_momentum_corrected\n","        ) + self.eps\n","        self.direction = (1 / bias_correction_ratio) * self.momentum\n","        return rgrad_norm\n","\n","    @torch.no_grad()\n","    def step(self, closure=None):\n","        W, E, R = self.param_groups[0][\"params\"]\n","\n","        x_k = self.direction.point\n","        x_k = (-self.param_groups[0][\"lr\"]) * self.direction + SFTuckerRiemannian.TangentVector(x_k)\n","        x_k = x_k.construct().round(self.rank)\n","\n","        W.data.add_(x_k.core - W)\n","        R.data.add_(x_k.regular_factors[0] - R)\n","        E.data.add_(x_k.shared_factor - E)\n","        \n","        self.step_t += 1"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-03-08T18:29:04.455814Z","iopub.status.busy":"2024-03-08T18:29:04.455310Z","iopub.status.idle":"2024-03-08T18:29:04.491450Z","shell.execute_reply":"2024-03-08T18:29:04.490508Z","shell.execute_reply.started":"2024-03-08T18:29:04.455763Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import torch\n","import time\n","from collections import defaultdict\n","from torch.optim.lr_scheduler import ExponentialLR\n","import argparse\n","\n","\n","def get_loss_fn(e_idx, r_idx, targets, criterion, C = 0):\n","    def loss_fn(T: SFTucker):\n","        relations = T.regular_factors[0][r_idx, :]\n","        subjects = T.shared_factor[e_idx, :]\n","        preds = torch.einsum(\"abc,da->dbc\", T.core, relations)\n","        preds = torch.bmm(subjects.view(-1, 1, subjects.shape[1]), preds).view(-1, subjects.shape[1])\n","        preds = preds @ T.shared_factor.T\n","        return criterion(torch.sigmoid(preds), targets) + C * T.norm()\n","\n","    return loss_fn\n","\n","\n","class Experiment:\n","    def __init__(self, learning_rate=0.0005, ent_vec_dim=200, rel_vec_dim=200,\n","                 num_iterations=500, batch_size=1024, decay_rate=0., label_smoothing=0.):\n","        self.learning_rate = learning_rate\n","        self.ent_vec_dim = ent_vec_dim\n","        self.rel_vec_dim = rel_vec_dim\n","        self.num_iterations = num_iterations\n","        self.batch_size = batch_size\n","        self.decay_rate = decay_rate\n","        self.label_smoothing = label_smoothing\n","        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","        self.criterion = torch.nn.BCELoss()\n","\n","    def get_data_idxs(self, data):\n","        data_idxs = [(self.entity_idxs[data[i][0]], self.relation_idxs[data[i][1]], self.entity_idxs[data[i][2]]) for i\n","                     in range(len(data))]\n","        return data_idxs\n","\n","    def get_er_vocab(self, data):\n","        er_vocab = defaultdict(list)\n","        for triple in data:\n","            er_vocab[(triple[0], triple[1])].append(triple[2])\n","        return er_vocab\n","\n","    def get_batch(self, er_vocab, er_vocab_pairs, idx):\n","        batch = er_vocab_pairs[idx:idx + self.batch_size]\n","        targets = np.zeros((len(batch), len(d.entities)))\n","        for idx, pair in enumerate(batch):\n","            targets[idx, er_vocab[pair]] = 1.\n","        targets = torch.FloatTensor(targets).to(self.device)\n","        return np.array(batch), targets\n","\n","    def evaluate(self, model, data):\n","        hits = []\n","        ranks = []\n","        for i in range(10):\n","            hits.append([])\n","\n","        test_data_idxs = self.get_data_idxs(data)\n","        er_vocab = self.get_er_vocab(self.get_data_idxs(d.data))\n","\n","        losses = []\n","        np.random.shuffle(test_data_idxs)\n","        for i in range(0, len(test_data_idxs), self.batch_size):\n","            data_batch, targets = self.get_batch(er_vocab, test_data_idxs, i)\n","            e1_idx = torch.tensor(data_batch[:, 0]).to(self.device)\n","            r_idx = torch.tensor(data_batch[:, 1]).to(self.device)\n","            e2_idx = torch.tensor(data_batch[:, 2]).to(self.device)\n","\n","            targets = ((1.0 - self.label_smoothing) * targets) + (1.0 / targets.size(1))\n","\n","            predictions = model.forward(e1_idx, r_idx)\n","\n","            losses.append(self.criterion(predictions, targets).item())\n","\n","            for j in range(data_batch.shape[0]):\n","                filt = er_vocab[(data_batch[j][0], data_batch[j][1])]\n","                target_value = predictions[j, e2_idx[j]].item()\n","                predictions[j, filt] = 0.0\n","                predictions[j, e2_idx[j]] = target_value\n","\n","            sort_values, sort_idxs = torch.sort(predictions, dim=1, descending=True)\n","\n","            sort_idxs = sort_idxs.cpu().numpy()\n","            for j in range(data_batch.shape[0]):\n","                rank = np.where(sort_idxs[j] == e2_idx[j].item())[0][0]\n","                ranks.append(rank + 1)\n","\n","                for hits_level in range(10):\n","                    if rank <= hits_level:\n","                        hits[hits_level].append(1.0)\n","                    else:\n","                        hits[hits_level].append(0.0)\n","\n","        # wandb.log({'val_loss': np.mean(losses)})\n","        # wandb.log({'Hits @10': np.mean(hits[9])})\n","        # wandb.log({'Hits @3': np.mean(hits[2])})\n","        # wandb.log({'Hits @1': np.mean(hits[0])})\n","        # wandb.log({'Mean reciprocal rank': np.mean(1. / np.array(ranks))})\n","        print('val_loss:', np.mean(losses))\n","        print('Hits @10: {0}'.format(np.mean(hits[9])))\n","        print('Hits @3: {0}'.format(np.mean(hits[2])))\n","        print('Hits @1: {0}'.format(np.mean(hits[0])))\n","        print('Mean reciprocal rank: {0}'.format(np.mean(1. / np.array(ranks))))\n","\n","    def train_and_eval(self):\n","        print(\"Training the TuckER model...\")\n","        self.entity_idxs = {d.entities[i]: i for i in range(len(d.entities))}\n","        self.relation_idxs = {d.relations[i]: i for i in range(len(d.relations))}\n","\n","        train_data_idxs = self.get_data_idxs(d.train_data)\n","        print(\"Number of training data points: %d\" % len(train_data_idxs))\n","\n","        model = SFTuckER(d, self.ent_vec_dim, self.rel_vec_dim)\n","\n","        model.init()\n","\n","        opt = SFTuckerAdam(model.parameters(), (self.rel_vec_dim, self.ent_vec_dim, self.ent_vec_dim), self.learning_rate)\n","        if self.decay_rate:\n","            scheduler = ExponentialLR(opt, self.decay_rate)\n","\n","        er_vocab = self.get_er_vocab(train_data_idxs)\n","        er_vocab_pairs = list(er_vocab.keys())\n","\n","        print(\"Starting training...\")\n","        for it in range(1, self.num_iterations + 1):\n","            print('Epoch:', it)\n","            start_train = time.time()\n","            losses = []\n","            np.random.shuffle(er_vocab_pairs)\n","            for j in range(0, len(er_vocab_pairs), self.batch_size):\n","                data_batch, targets = self.get_batch(er_vocab, er_vocab_pairs, j)\n","                opt.zero_grad()\n","                e1_idx = torch.tensor(data_batch[:, 0]).to(self.device)\n","                r_idx = torch.tensor(data_batch[:, 1]).to(self.device)\n","\n","                targets = ((1.0 - self.label_smoothing) * targets) + (1.0 / targets.size(1))\n","\n","                loss_fn = get_loss_fn(e1_idx, r_idx, targets, self.criterion)\n","                grad_norm = opt.fit(loss_fn, model)\n","                opt.step()\n","                opt.zero_grad(set_to_none=True)\n","\n","                loss = opt.loss.detach()\n","                # wandb.log({'train_step_loss': loss.item()})\n","                print(j / self.batch_size, loss)\n","\n","                losses.append(loss.item())\n","            if self.decay_rate:\n","                scheduler.step()\n","#             print('time:', time.time() - start_train)\n","            # wandb.log({'train_mean_loss': np.mean(losses)})\n","            print(np.mean(losses))\n","            with torch.no_grad():\n","                print(\"Validation:\")\n","                self.evaluate(model, d.valid_data)\n","#                 if it % 5 == 0:\n","#                     print(\"Test:\")\n","#                     self.evaluate(model, d.test_data)"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-03-08T18:29:05.587325Z","iopub.status.busy":"2024-03-08T18:29:05.586974Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training the TuckER model...\n","Number of training data points: 544230\n","Starting training...\n","Epoch: 1\n","0.0 tensor(0.6932)\n","1.0 tensor(49.4853)\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[27], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m d \u001b[38;5;241m=\u001b[39m Data(data_dir\u001b[38;5;241m=\u001b[39mdata_dir, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     20\u001b[0m experiment \u001b[38;5;241m=\u001b[39m Experiment(num_iterations\u001b[38;5;241m=\u001b[39mnum_iterations, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, learning_rate\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m     21\u001b[0m                         decay_rate\u001b[38;5;241m=\u001b[39mdr, ent_vec_dim\u001b[38;5;241m=\u001b[39medim, rel_vec_dim\u001b[38;5;241m=\u001b[39mrdim, label_smoothing\u001b[38;5;241m=\u001b[39mlabel_smoothing)\n\u001b[0;32m---> 22\u001b[0m \u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_and_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[26], line 141\u001b[0m, in \u001b[0;36mExperiment.train_and_eval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m get_loss_fn(e1_idx, r_idx, targets, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n\u001b[1;32m    140\u001b[0m grad_norm \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39mfit(loss_fn, model)\n\u001b[0;32m--> 141\u001b[0m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    144\u001b[0m loss \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mdetach()\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[25], line 118\u001b[0m, in \u001b[0;36mSFTuckerAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    116\u001b[0m x_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirection\u001b[38;5;241m.\u001b[39mpoint\n\u001b[1;32m    117\u001b[0m x_k \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirection \u001b[38;5;241m+\u001b[39m SFTuckerRiemannian\u001b[38;5;241m.\u001b[39mTangentVector(x_k)\n\u001b[0;32m--> 118\u001b[0m x_k \u001b[38;5;241m=\u001b[39m \u001b[43mx_k\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrank\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m W\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39madd_(x_k\u001b[38;5;241m.\u001b[39mcore \u001b[38;5;241m-\u001b[39m W)\n\u001b[1;32m    121\u001b[0m R\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39madd_(x_k\u001b[38;5;241m.\u001b[39mregular_factors[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m R)\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tucker_riemopt/sf_tucker/sf_tucker.py:276\u001b[0m, in \u001b[0;36mSFTucker.round\u001b[0;34m(self, max_rank, eps)\u001b[0m\n\u001b[1;32m    274\u001b[0m shared_Q, shared_R \u001b[38;5;241m=\u001b[39m back\u001b[38;5;241m.\u001b[39mqr(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshared_factor)\n\u001b[1;32m    275\u001b[0m intermediate_core \u001b[38;5;241m=\u001b[39m SFTucker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcore, intermediate_factors, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_shared_factors, shared_R)\u001b[38;5;241m.\u001b[39mto_dense()\n\u001b[0;32m--> 276\u001b[0m intermediate_core \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sf_hosvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_core\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msft_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_rank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     max_rank \u001b[38;5;241m=\u001b[39m intermediate_core\u001b[38;5;241m.\u001b[39mrank\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tucker_riemopt/sf_tucker/sf_tucker.py:75\u001b[0m, in \u001b[0;36mSFTucker.__sf_hosvd\u001b[0;34m(cls, dense_tensor, ds, sft_rank, eps)\u001b[0m\n\u001b[1;32m     73\u001b[0m     core_concat \u001b[38;5;241m=\u001b[39m back\u001b[38;5;241m.\u001b[39mconcatenate([core_concat, unfolding], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m core_concat \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m unfolding\n\u001b[1;32m     74\u001b[0m     factor_letters\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mascii_letters[dt\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39mi]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mascii_letters[d\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39mdt\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39mi]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m u, s, _ \u001b[38;5;241m=\u001b[39m \u001b[43mback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_concat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m u \u001b[38;5;241m=\u001b[39m truncate_unfolding(u, s, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     77\u001b[0m factors\u001b[38;5;241m.\u001b[39mextend([u] \u001b[38;5;241m*\u001b[39m ds)\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tucker_riemopt/backend/__init__.py:96\u001b[0m, in \u001b[0;36mBackendManager.dispatch_backend_method.<locals>.wrapped_backend_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_backend_method\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_THREAD_LOCAL_DATA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["dataset = \"FB15k-237\"\n","num_iterations = 500\n","batch_size = 64\n","lr = 1e9\n","dr = 1.0\n","edim = 200\n","rdim = 200\n","label_smoothing = 0.1\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","data_dir = \"data/%s/\" % dataset\n","torch.backends.cudnn.deterministic = True\n","seed = 20\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(seed)\n","d = Data(data_dir=data_dir, reverse=True)\n","experiment = Experiment(num_iterations=num_iterations, batch_size=batch_size, learning_rate=lr,\n","                        decay_rate=dr, ent_vec_dim=edim, rel_vec_dim=rdim, label_smoothing=label_smoothing)\n","experiment.train_and_eval()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4563116,"sourceId":7794551,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
