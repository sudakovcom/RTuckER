{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-09T20:40:57.489451Z","iopub.status.busy":"2024-03-09T20:40:57.489184Z","iopub.status.idle":"2024-03-09T20:40:57.506480Z","shell.execute_reply":"2024-03-09T20:40:57.505678Z","shell.execute_reply.started":"2024-03-09T20:40:57.489427Z"},"trusted":true},"outputs":[],"source":["class Data:\n","    def __init__(self, data_dir=\"data/FB15k-237/\", reverse=False):\n","        self.train_data = self.load_data(data_dir, \"train\", reverse=reverse)\n","        self.valid_data = self.load_data(data_dir, \"valid\", reverse=reverse)\n","        self.test_data = self.load_data(data_dir, \"test\", reverse=reverse)\n","        self.data = self.train_data + self.valid_data + self.test_data\n","        self.entities = self.get_entities(self.data)\n","        self.relations = self.get_relations(self.data)\n","        self.train_relations = self.get_relations(self.train_data)\n","        self.valid_relations = self.get_relations(self.valid_data)\n","        self.test_relations = self.get_relations(self.test_data)\n","\n","    @staticmethod\n","    def load_data(data_dir, data_type=\"train\", reverse=False):\n","        with open(\"%s%s.txt\" % (data_dir, data_type), \"r\") as f:\n","            data = f.read().strip().split(\"\\n\")\n","            data = [i.split() for i in data]\n","            if reverse:\n","                data += [[i[2], i[1] + \"_reverse\", i[0]] for i in data]\n","        return data\n","\n","    @staticmethod\n","    def get_relations(data):\n","        relations = sorted(list(set([d[1] for d in data])))\n","        return relations\n","\n","    @staticmethod\n","    def get_entities(data):\n","        entities = sorted(list(set([d[0] for d in data] + [d[2] for d in data])))\n","        return entities\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T20:42:39.413531Z","iopub.status.busy":"2024-03-09T20:42:39.412708Z","iopub.status.idle":"2024-03-09T20:42:52.383217Z","shell.execute_reply":"2024-03-09T20:42:52.382038Z","shell.execute_reply.started":"2024-03-09T20:42:39.413499Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tucker_riemopt\n","  Downloading tucker_riemopt-1.0.1-py3-none-any.whl.metadata (3.3 kB)\n","Requirement already satisfied: numpy<2.0.0,>=1.21.4 in /opt/conda/lib/python3.10/site-packages (from tucker_riemopt) (1.26.4)\n","Requirement already satisfied: opt-einsum<4.0.0,>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from tucker_riemopt) (3.3.0)\n","Requirement already satisfied: scipy<2.0.0,>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from tucker_riemopt) (1.11.4)\n","Downloading tucker_riemopt-1.0.1-py3-none-any.whl (30 kB)\n","Installing collected packages: tucker_riemopt\n","Successfully installed tucker_riemopt-1.0.1\n"]}],"source":["! pip3 install tucker_riemopt"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T20:42:52.385291Z","iopub.status.busy":"2024-03-09T20:42:52.384942Z","iopub.status.idle":"2024-03-09T20:42:56.869030Z","shell.execute_reply":"2024-03-09T20:42:56.867570Z","shell.execute_reply.started":"2024-03-09T20:42:52.385260Z"},"trusted":true},"outputs":[],"source":["import torch\n","import numpy as np\n","from torch import nn\n","from torch.nn.init import xavier_normal_\n","from tucker_riemopt import SFTucker\n","\n","from torch.optim import Optimizer\n","from tucker_riemopt import SFTuckerRiemannian"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T20:43:12.972743Z","iopub.status.busy":"2024-03-09T20:43:12.971924Z","iopub.status.idle":"2024-03-09T20:43:12.995790Z","shell.execute_reply":"2024-03-09T20:43:12.994580Z","shell.execute_reply.started":"2024-03-09T20:43:12.972710Z"},"trusted":true},"outputs":[],"source":["class SFTuckER:\n","    def __init__(self, d, d1, d2):\n","        device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","        self.rank = (d2, d1, d1)\n","        self.E = torch.rand((len(d.entities), d1), device=device)\n","        self.R = torch.rand((len(d.relations), d2), device=device)\n","        self.W = torch.tensor(np.random.uniform(-1, 1, (d2, d1, d1)), dtype=torch.float, device=device)\n","        \n","    def parameters(self):\n","        return nn.ParameterList([self.W, self.E, self.R])\n","\n","    def init(self):\n","        xavier_normal_(self.E.data)\n","        xavier_normal_(self.R.data)\n","        # with torch.no_grad():\n","        #     self.E.weight.data = torch.linalg.qr(self.E.weight)[0]\n","        #     self.R.weight.data = torch.linalg.qr(self.R.weight)[0]\n","\n","    def forward(self, e_idx, r_idx):\n","        relations = self.R[r_idx, :]\n","        subjects = self.E[e_idx, :]\n","        preds = torch.einsum(\"abc,da->dbc\", self.W, relations)\n","        preds = torch.bmm(subjects.view(-1, 1, subjects.shape[1]), preds).view(-1, subjects.shape[1])\n","        preds = preds @ self.E.T\n","        return torch.sigmoid(preds)\n","\n","\n","class RGD(Optimizer):\n","    def __init__(self, model_parameters, rank, max_lr):\n","        self.rank = rank\n","        self.max_lr = max_lr\n","        self.lr = max_lr\n","        self.direction = None\n","        self.loss = None\n","\n","        defaults = dict(rank=rank, max_lr=self.max_lr, lr=self.lr)\n","        params = model_parameters\n","        super().__init__(params, defaults)\n","\n","    def fit(self, loss_fn, model, normalize_grad=False):\n","        x_k = SFTucker(model.W.data, [model.R.data], num_shared_factors=2, shared_factor=model.E.data)\n","        rgrad, self.loss = SFTuckerRiemannian.grad(loss_fn, x_k)\n","        rgrad_norm = rgrad.norm().detach()\n","\n","        if normalize_grad:\n","            normalizer = normalize_grad / rgrad_norm\n","        else:\n","            normalizer = 1\n","\n","        self.direction = normalizer * rgrad\n","        return rgrad_norm\n","\n","    @torch.no_grad()\n","    def step(self):\n","        W, E, R = self.param_groups[0][\"params\"]\n","\n","        x_k = self.direction.point\n","        x_k = (-self.param_groups[0][\"lr\"]) * self.direction + SFTuckerRiemannian.TangentVector(x_k)\n","        x_k = x_k.construct().round(self.rank)\n","\n","        W.data.add_(x_k.core - W)\n","        R.data.add_(x_k.regular_factors[0] - R)\n","        E.data.add_(x_k.shared_factor - E)\n","\n","\n","\n","class SFTuckerAdam(RGD):\n","    def __init__(self, params, rank, max_lr, betas=(0.9, 0.999), eps=1e-8, step_velocity=1):\n","        super().__init__(params, rank, max_lr)\n","        self.betas = betas\n","        self.eps = eps\n","        self.step_velocity = step_velocity\n","        \n","        self.momentum = None\n","        self.second_momentum = torch.zeros(1, device=\"cuda\")\n","        \n","        self.step_t = 1\n","\n","    def fit(self, loss_fn, model, normalize_grad = 1.):\n","        x_k = SFTucker(model.W.data, [model.R.data], num_shared_factors=2, shared_factor=model.E.data)\n","        rgrad, self.loss = SFTuckerRiemannian.grad(loss_fn, x_k)\n","        rgrad_norm = rgrad.norm().detach()\n","        if self.momentum is not None:\n","            self.momentum = SFTuckerRiemannian.project(x_k, self.momentum.construct())\n","            self.momentum = self.betas[0] * self.momentum + (1 - self.betas[0]) * rgrad\n","        else:\n","            self.momentum = (1 - self.betas[0]) * rgrad\n","        self.second_momentum = self.betas[1] * self.second_momentum + (1 - self.betas[1]) * rgrad_norm ** 2\n","        second_momentum_corrected = self.second_momentum / (1 - self.betas[1] ** (self.step_t // self.step_velocity + 1))\n","        bias_correction_ratio = (1 - self.betas[0] ** (self.step_t // self.step_velocity + 1)) * torch.sqrt(\n","            second_momentum_corrected\n","        ) + self.eps\n","        self.direction = (1 / bias_correction_ratio) * self.momentum\n","        return rgrad_norm\n","\n","    @torch.no_grad()\n","    def step(self, closure=None):\n","        W, E, R = self.param_groups[0][\"params\"]\n","\n","        x_k = self.direction.point\n","        x_k = (-self.param_groups[0][\"lr\"]) * self.direction + SFTuckerRiemannian.TangentVector(x_k)\n","        x_k = x_k.construct().round(self.rank)\n","\n","        W.data.add_(x_k.core - W)\n","        R.data.add_(x_k.regular_factors[0] - R)\n","        E.data.add_(x_k.shared_factor - E)\n","        \n","        self.step_t += 1\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T20:44:43.078924Z","iopub.status.busy":"2024-03-09T20:44:43.078551Z","iopub.status.idle":"2024-03-09T20:44:43.126477Z","shell.execute_reply":"2024-03-09T20:44:43.125499Z","shell.execute_reply.started":"2024-03-09T20:44:43.078895Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import torch\n","import time\n","from collections import defaultdict\n","from torch.optim.lr_scheduler import ExponentialLR\n","import argparse\n","\n","\n","def get_loss_fn(e_idx, r_idx, targets, criterion):\n","    def loss_fn(T: SFTucker):\n","        relations = T.regular_factors[0][r_idx, :]\n","        subjects = T.shared_factor[e_idx, :]\n","        preds = torch.einsum(\"abc,da->dbc\", T.core, relations)\n","        preds = torch.bmm(subjects.view(-1, 1, subjects.shape[1]), preds).view(-1, subjects.shape[1])\n","        preds = preds @ T.shared_factor.T\n","        return criterion(torch.sigmoid(preds), targets)\n","\n","    return loss_fn\n","\n","\n","class Experiment:\n","    def __init__(self, learning_rate=0.0005, ent_vec_dim=200, rel_vec_dim=200,\n","                 num_iterations=500, batch_size=1024, decay_rate=0., label_smoothing=0.):\n","        self.learning_rate = learning_rate\n","        self.ent_vec_dim = ent_vec_dim\n","        self.rel_vec_dim = rel_vec_dim\n","        self.num_iterations = num_iterations\n","        self.batch_size = batch_size\n","        self.decay_rate = decay_rate\n","        self.label_smoothing = label_smoothing\n","        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","        self.criterion = torch.nn.BCELoss()\n","\n","    def get_data_idxs(self, data):\n","        data_idxs = [(self.entity_idxs[data[i][0]], self.relation_idxs[data[i][1]], self.entity_idxs[data[i][2]]) for i\n","                     in range(len(data))]\n","        return data_idxs\n","\n","    def get_er_vocab(self, data):\n","        er_vocab = defaultdict(list)\n","        for triple in data:\n","            er_vocab[(triple[0], triple[1])].append(triple[2])\n","        return er_vocab\n","\n","    def get_batch(self, er_vocab, er_vocab_pairs, idx):\n","        batch = er_vocab_pairs[idx:idx + self.batch_size]\n","        targets = np.zeros((len(batch), len(d.entities)))\n","        for idx, pair in enumerate(batch):\n","            targets[idx, er_vocab[pair]] = 1.\n","        targets = torch.FloatTensor(targets).to(self.device)\n","        return np.array(batch), targets\n","\n","    def evaluate(self, model, data):\n","        hits = []\n","        ranks = []\n","        for i in range(10):\n","            hits.append([])\n","\n","        test_data_idxs = self.get_data_idxs(data)\n","        er_vocab = self.get_er_vocab(self.get_data_idxs(d.data))\n","\n","        losses = []\n","        np.random.shuffle(test_data_idxs)\n","        for i in range(0, len(test_data_idxs), self.batch_size):\n","            data_batch, targets = self.get_batch(er_vocab, test_data_idxs, i)\n","            e1_idx = torch.tensor(data_batch[:, 0]).to(self.device)\n","            r_idx = torch.tensor(data_batch[:, 1]).to(self.device)\n","            e2_idx = torch.tensor(data_batch[:, 2]).to(self.device)\n","\n","            targets = ((1.0 - self.label_smoothing) * targets) + (1.0 / targets.size(1))\n","\n","            predictions = model.forward(e1_idx, r_idx)\n","\n","            losses.append(self.criterion(predictions, targets).item())\n","\n","            for j in range(data_batch.shape[0]):\n","                filt = er_vocab[(data_batch[j][0], data_batch[j][1])]\n","                target_value = predictions[j, e2_idx[j]].item()\n","                predictions[j, filt] = 0.0\n","                predictions[j, e2_idx[j]] = target_value\n","\n","            sort_values, sort_idxs = torch.sort(predictions, dim=1, descending=True)\n","\n","            sort_idxs = sort_idxs.cpu().numpy()\n","            for j in range(data_batch.shape[0]):\n","                rank = np.where(sort_idxs[j] == e2_idx[j].item())[0][0]\n","                ranks.append(rank + 1)\n","\n","                for hits_level in range(10):\n","                    if rank <= hits_level:\n","                        hits[hits_level].append(1.0)\n","                    else:\n","                        hits[hits_level].append(0.0)\n","\n","        print('val_loss:', np.mean(losses))\n","        print('Hits @10: {0}'.format(np.mean(hits[9])))\n","        print('Hits @3: {0}'.format(np.mean(hits[2])))\n","        print('Hits @1: {0}'.format(np.mean(hits[0])))\n","        print('Mean reciprocal rank: {0}'.format(np.mean(1. / np.array(ranks))))\n","\n","    def train_and_eval(self):\n","        print(\"Training the TuckER model...\")\n","        self.entity_idxs = {d.entities[i]: i for i in range(len(d.entities))}\n","        self.relation_idxs = {d.relations[i]: i for i in range(len(d.relations))}\n","\n","        train_data_idxs = self.get_data_idxs(d.train_data)\n","        print(\"Number of training data points: %d\" % len(train_data_idxs))\n","\n","        model = SFTuckER(d, self.ent_vec_dim, self.rel_vec_dim)\n","\n","        model.init()\n","\n","        opt = RGD(model.parameters(), (self.rel_vec_dim, self.ent_vec_dim, self.ent_vec_dim), self.learning_rate)\n","        if self.decay_rate:\n","            scheduler = ExponentialLR(opt, self.decay_rate)\n","\n","        er_vocab = self.get_er_vocab(train_data_idxs)\n","        er_vocab_pairs = list(er_vocab.keys())\n","\n","        print(\"Starting training...\")\n","        for it in range(1, self.num_iterations + 1):\n","            print('Epoch:', it)\n","            start_train = time.time()\n","            losses = []\n","            np.random.shuffle(er_vocab_pairs)\n","            for j in range(0, len(er_vocab_pairs), self.batch_size):\n","                data_batch, targets = self.get_batch(er_vocab, er_vocab_pairs, j)\n","                opt.zero_grad()\n","                e1_idx = torch.tensor(data_batch[:, 0]).to(self.device)\n","                r_idx = torch.tensor(data_batch[:, 1]).to(self.device)\n","\n","                targets = ((1.0 - self.label_smoothing) * targets) + (1.0 / targets.size(1))\n","\n","                loss_fn = get_loss_fn(e1_idx, r_idx, targets, self.criterion)\n","                grad_norm = opt.fit(loss_fn, model)\n","                opt.step()\n","                opt.zero_grad(set_to_none=True)\n","\n","                loss = opt.loss.detach()\n","                print(j / self.batch_size, loss)\n","\n","                losses.append(loss.item())\n","            if self.decay_rate:\n","                scheduler.step()\n","            # print('time:', time.time() - start_train)\n","            print(np.mean(losses))\n","            with torch.no_grad():\n","                print(\"Validation:\")\n","                self.evaluate(model, d.valid_data)\n","#                 if it % 5 == 0:\n","#                     print(\"Test:\")\n","#                     self.evaluate(model, d.test_data)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-03-09T20:49:30.548074Z","iopub.status.busy":"2024-03-09T20:49:30.547418Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training the TuckER model...\n","Number of training data points: 544230\n","Starting training...\n","Epoch: 1\n","0.0 tensor(0.6932)\n","1.0 tensor(0.6944)\n","2.0 tensor(0.6862)\n","3.0 tensor(0.6973)\n","4.0 tensor(0.6869)\n","5.0 tensor(0.7258)\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m d \u001b[38;5;241m=\u001b[39m Data(data_dir\u001b[38;5;241m=\u001b[39mdata_dir, reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     18\u001b[0m experiment \u001b[38;5;241m=\u001b[39m Experiment(num_iterations\u001b[38;5;241m=\u001b[39mnum_iterations, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, learning_rate\u001b[38;5;241m=\u001b[39mlr,\n\u001b[1;32m     19\u001b[0m                         decay_rate\u001b[38;5;241m=\u001b[39mdr, ent_vec_dim\u001b[38;5;241m=\u001b[39medim, rel_vec_dim\u001b[38;5;241m=\u001b[39mrdim, label_smoothing\u001b[38;5;241m=\u001b[39mlabel_smoothing)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_and_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[7], line 136\u001b[0m, in \u001b[0;36mExperiment.train_and_eval\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    134\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m get_loss_fn(e1_idx, r_idx, targets, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n\u001b[1;32m    135\u001b[0m grad_norm \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39mfit(loss_fn, model)\n\u001b[0;32m--> 136\u001b[0m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m opt\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    139\u001b[0m loss \u001b[38;5;241m=\u001b[39m opt\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mdetach()\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:75\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m instance\u001b[38;5;241m.\u001b[39m_step_count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     74\u001b[0m wrapped \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__get__\u001b[39m(instance, \u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/optim/optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m             )\n\u001b[0;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[6], line 59\u001b[0m, in \u001b[0;36mRGD.step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m x_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirection\u001b[38;5;241m.\u001b[39mpoint\n\u001b[1;32m     58\u001b[0m x_k \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdirection \u001b[38;5;241m+\u001b[39m SFTuckerRiemannian\u001b[38;5;241m.\u001b[39mTangentVector(x_k)\n\u001b[0;32m---> 59\u001b[0m x_k \u001b[38;5;241m=\u001b[39m \u001b[43mx_k\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrank\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m W\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39madd_(x_k\u001b[38;5;241m.\u001b[39mcore \u001b[38;5;241m-\u001b[39m W)\n\u001b[1;32m     62\u001b[0m R\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39madd_(x_k\u001b[38;5;241m.\u001b[39mregular_factors[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m R)\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tucker_riemopt/sf_tucker/sf_tucker.py:276\u001b[0m, in \u001b[0;36mSFTucker.round\u001b[0;34m(self, max_rank, eps)\u001b[0m\n\u001b[1;32m    274\u001b[0m shared_Q, shared_R \u001b[38;5;241m=\u001b[39m back\u001b[38;5;241m.\u001b[39mqr(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshared_factor)\n\u001b[1;32m    275\u001b[0m intermediate_core \u001b[38;5;241m=\u001b[39m SFTucker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcore, intermediate_factors, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_shared_factors, shared_R)\u001b[38;5;241m.\u001b[39mto_dense()\n\u001b[0;32m--> 276\u001b[0m intermediate_core \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__sf_hosvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_core\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msft_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_rank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_rank \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     max_rank \u001b[38;5;241m=\u001b[39m intermediate_core\u001b[38;5;241m.\u001b[39mrank\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tucker_riemopt/sf_tucker/sf_tucker.py:75\u001b[0m, in \u001b[0;36mSFTucker.__sf_hosvd\u001b[0;34m(cls, dense_tensor, ds, sft_rank, eps)\u001b[0m\n\u001b[1;32m     73\u001b[0m     core_concat \u001b[38;5;241m=\u001b[39m back\u001b[38;5;241m.\u001b[39mconcatenate([core_concat, unfolding], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m core_concat \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m unfolding\n\u001b[1;32m     74\u001b[0m     factor_letters\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mascii_letters[dt\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39mi]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mascii_letters[d\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39mdt\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39mi]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m u, s, _ \u001b[38;5;241m=\u001b[39m \u001b[43mback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcore_concat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_matrices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m u \u001b[38;5;241m=\u001b[39m truncate_unfolding(u, s, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     77\u001b[0m factors\u001b[38;5;241m.\u001b[39mextend([u] \u001b[38;5;241m*\u001b[39m ds)\n","File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tucker_riemopt/backend/__init__.py:96\u001b[0m, in \u001b[0;36mBackendManager.dispatch_backend_method.<locals>.wrapped_backend_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_backend_method\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_THREAD_LOCAL_DATA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["dataset = \"FB15k-237\"\n","num_iterations = 500\n","batch_size = 64\n","lr = 1e9\n","dr = 1.0\n","edim = 200\n","rdim = 200\n","label_smoothing = 0.1\n","\n","data_dir = \"data/%s/\" % dataset\n","torch.backends.cudnn.deterministic = True\n","seed = 20\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(seed)\n","d = Data(data_dir=data_dir, reverse=True)\n","experiment = Experiment(num_iterations=num_iterations, batch_size=batch_size, learning_rate=lr,\n","                        decay_rate=dr, ent_vec_dim=edim, rel_vec_dim=rdim, label_smoothing=label_smoothing)\n","experiment.train_and_eval()"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4563116,"sourceId":7794551,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
